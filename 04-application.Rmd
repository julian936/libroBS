# Metodología Box-Jenkins y Modelos ARIMA {#box-jenkins-arima}

## Introducción

En el capítulo anterior exploramos los modelos de suavizamiento exponencial y Holt-Winters para el análisis y pronóstico de series de tiempo. Ahora profundizaremos en la metodología Box-Jenkins y los modelos ARIMA (AutoRegressive Integrated Moving Average), que constituyen uno de los enfoques más robustos y ampliamente utilizados para el modelado de series temporales.

La metodología Box-Jenkins, desarrollada por George Box y Gwilym Jenkins en 1970, proporciona un marco sistemático para identificar, estimar y validar modelos ARIMA. Este enfoque iterativo consta de cuatro fases principales:

1. **Identificación**: Determinar si la serie es estacionaria y seleccionar los órdenes apropiados del modelo
2. **Estimación**: Calcular los parámetros del modelo seleccionado
3. **Diagnóstico**: Verificar que el modelo se ajuste adecuadamente a los datos
4. **Pronóstico**: Utilizar el modelo validado para realizar predicciones

```
╔══════════════════════════════════════════════════════════════════╗
║          METODOLOGÍA BOX-JENKINS Y MODELOS ARIMA/SARIMA          ║
╚══════════════════════════════════════════════════════════════════╝
                           │
                           ▼
┌──────────────────────────────────────────────────────────────────┐
│                   ENTRADA: DATOS COMPLETOS                        │
│  • Series de precios: AAPL, MSFT, TSLA, PFE, MRNA, JNJ          │
│  • Período: 2015-2025 (~2600 observaciones diarias)             │
│  • Transformación: log(precios) para estabilizar varianza       │
│  • Objetivo: Identificar, estimar, validar y pronosticar        │
└────────────────────┬─────────────────────────────────────────────┘
                     │
                     ▼
╔══════════════════════════════════════════════════════════════════╗
║                  FASE 1: IDENTIFICACIÓN DEL MODELO               ║
╚══════════════════════════════════════════════════════════════════╝
                     │
                     ▼
┌──────────────────────────────────────────────────────────────────┐
│         PASO 1.1: ANÁLISIS DE ESTACIONARIEDAD                    │
│  ¿La serie tiene media y varianza constantes en el tiempo?      │
└────────────────────┬─────────────────────────────────────────────┘
                     │
        Aplicar 3 pruebas estadísticas:
                     │
    ┌────────────────┼────────────────┐
    │                │                │
    ▼                ▼                ▼
┌─────────┐    ┌─────────┐    ┌─────────┐
│Prueba   │    │Prueba   │    │Prueba   │
│  ADF    │    │  KPSS   │    │   PP    │
│(Dickey- │    │(Kwiat-  │    │(Phillips│
│Fuller)  │    │kowski)  │    │-Perron) │
└────┬────┘    └────┬────┘    └────┬────┘
     │              │              │
     │  H₀: No estacionaria       │
     │  H₁: Estacionaria          │
     └──────────────┴──────────────┘
                     │
                     ▼
              ¿Es estacionaria?
                     │
        ┌────────────┴────────────┐
        │ NO                      │ SÍ
        ▼                         ▼
┌───────────────┐         ┌──────────────┐
│Transformación │         │  Continuar   │
│log(precios)   │────────▶│  al paso 1.2 │
└───────────────┘         └──────┬───────┘
                                 │
                                 ▼
┌──────────────────────────────────────────────────────────────────┐
│         PASO 1.2: ANÁLISIS ACF Y PACF                            │
│  Identificar órdenes AR (p) y MA (q)                             │
└────────────────────┬─────────────────────────────────────────────┘
                     │
    ┌────────────────┴────────────────┐
    │                                 │
    ▼                                 ▼
┌─────────────────────┐      ┌──────────────────────┐
│   Función ACF       │      │   Función PACF       │
│(Autocorrelación)    │      │(Autocorrel. Parcial) │
│                     │      │                      │
│• Decae exponencial  │      │• Corte después lag p │
│  → componente MA    │      │  → orden AR          │
│• Corte lag q        │      │• Decae exponencial   │
│  → orden MA         │      │  → componente AR     │
└──────────┬──────────┘      └──────────┬───────────┘
           │                            │
           └────────────┬───────────────┘
                        │
                        ▼
              Revisar lags 7, 14, 21...
              ¿Hay patrón estacional?
                        │
           ┌────────────┴────────────┐
           │ NO                      │ SÍ (s=7, s=252, etc.)
           ▼                         ▼
    Modelos ARMA              Modelos SARIMA
    ARIMA(p,d,q)             ARIMA(p,d,q)(P,D,Q)[s]
           │                         │
           └────────────┬────────────┘
                        │
                        ▼
┌──────────────────────────────────────────────────────────────────┐
│         PASO 1.3: MODELOS CANDIDATOS                             │
│  Basado en ACF/PACF, proponer múltiples modelos                  │
└────────────────────┬─────────────────────────────────────────────┘
                     │
    **Modelos ARIMA iniciales:**
    • ARIMA(1,1,0) - AR con diferenciación
    • ARIMA(0,1,1) - MA con diferenciación
    • ARIMA(1,1,1) - Mixto
    • ARIMA(2,1,1), ARIMA(1,1,2) - Órdenes mayores
                     │
                     ▼
╔══════════════════════════════════════════════════════════════════╗
║                 FASE 2: ESTIMACIÓN DE PARÁMETROS                 ║
╚══════════════════════════════════════════════════════════════════╝
                     │
                     ▼
┌──────────────────────────────────────────────────────────────────┐
│         PASO 2.1: ESTIMACIÓN DE CADA MODELO                      │
│  Método: Máxima Verosimilitud (MLE)                              │
└────────────────────┬─────────────────────────────────────────────┘
                     │
    Para cada modelo candidato:
    1. Estimar parámetros (ϕ, θ, μ)
    2. Calcular log-likelihood
    3. Obtener criterios de información
                     │
                     ▼
┌──────────────────────────────────────────────────────────────────┐
│         PASO 2.2: COMPARACIÓN DE MODELOS                         │
│  Criterios: AIC, AICc, BIC                                       │
└────────────────────┬─────────────────────────────────────────────┘
                     │
    AIC = -2*log(L) + 2*k
    BIC = -2*log(L) + k*log(n)
                     │
              Seleccionar modelo
              con menor AIC/BIC
                     │
                     ▼
╔══════════════════════════════════════════════════════════════════╗
║                 FASE 3: DIAGNÓSTICO Y VALIDACIÓN                 ║
╚══════════════════════════════════════════════════════════════════╝
                     │
                     ▼
┌──────────────────────────────────────────────────────────────────┐
│         PASO 3.1: ANÁLISIS DE RESIDUOS                           │
│  Los residuos deben comportarse como RUIDO BLANCO                │
└────────────────────┬─────────────────────────────────────────────┘
                     │
    Requisitos del ruido blanco:
    ✓ Media = 0
    ✓ Varianza constante
    ✓ No autocorrelacionados
    ✓ Distribución normal
                     │
                     ▼
┌──────────────────────────────────────────────────────────────────┐
│         PASO 3.2: PRUEBA DE LJUNG-BOX                            │
│  H₀: Los residuos NO están autocorrelacionados                  │
└────────────────────┬─────────────────────────────────────────────┘
                     │
    Box.test(residuos, lag=20, type="Ljung-Box")
                     │
                     ▼
              p-valor > 0.05?
                     │
        ┌────────────┴────────────┐
        │ NO (p < 0.05)           │ SÍ (p > 0.05)
        ▼                         ▼
┌───────────────┐         ┌──────────────┐
│ Probar SARIMA │         │ Modelo       │
│ con componente│         │ adecuado ✓   │
│ estacional    │         │ Continuar a  │
└───────────────┘         │ Fase 4       │
                          └──────────────┘
                                 │
                                 ▼
╔══════════════════════════════════════════════════════════════════╗
║                 FASE 4: PRONÓSTICO Y APLICACIÓN                  ║
╚══════════════════════════════════════════════════════════════════╝
                     │
                     ▼
┌──────────────────────────────────────────────────────────────────┐
│         PASO 4.1: GENERACIÓN DE PRONÓSTICOS                      │
│  Proyectar h pasos adelante con intervalos de confianza         │
└────────────────────┬─────────────────────────────────────────────┘
                     │
    forecast(modelo_final, h = 30)
                     │
    Salida:
    • Pronóstico puntual: ŷ(t+h)
    • Intervalo 80%: [Lo 80, Hi 80]
    • Intervalo 95%: [Lo 95, Hi 95]
                     │
                     ▼
┌──────────────────────────────────────────────────────────────────┐
│         PASO 4.2: TRANSFORMACIÓN INVERSA                         │
│  Si usamos log(y), aplicar exp() para volver a escala original  │
└────────────────────┬─────────────────────────────────────────────┘
                     │
    pronos_original = exp(pronos_log)
                     │
                     ▼
╔══════════════════════════════════════════════════════════════════╗
║                    RESULTADOS ESPERADOS                          ║
║                                                                  ║
║  **Hallazgos sobre estacionariedad:**                            ║
║    • log(precios) es estacionaria (ADF: p < 0.05)               ║
║    • Transformación logarítmica estabiliza varianza             ║
║                                                                  ║
║  **Mejor modelo típico:**                                        ║
║    ARIMA(1,1,1) o ARIMA(2,1,1)                                  ║
║                                                                  ║
║  **Ventajas de ARIMA vs Holt-Winters:**                         ║
║    ✓ Captura autocorrelación compleja                           ║
║    ✓ Diagnóstico formal con pruebas estadísticas                ║
║    ✓ Componente estacional opcional y flexible                  ║
╚══════════════════════════════════════════════════════════════════╝
```

Los modelos ARIMA son particularmente efectivos para series que exhiben patrones de autocorrelación y tendencias. En este capítulo aplicaremos la metodología Box-Jenkins a las mismas series de precios de acciones que analizamos con Holt-Winters.

## Fase 1: Identificación del Modelo

### Carga y preparación de datos

```{r setup-chapter, message=FALSE, warning=FALSE}
# Cargar librerías necesarias
library(forecast)
library(tseries)
library(ggplot2)
library(dplyr)
library(readxl)
library(knitr)
library(lubridate)
library(gridExtra)
```

```{r carga-datos, message=FALSE, warning=FALSE}
# Leer datos desde Excel
datos <- read_excel("datos_yahoo/datasets/datos_completos.xlsx") %>%
  mutate(Fecha = as.Date(Fecha))

# Información general
cat("Total de observaciones:", nrow(datos), "\n")
cat("Período:", min(datos$Fecha), "a", max(datos$Fecha), "\n")
cat("Activos:", paste(unique(datos$Ticker), collapse = ", "), "\n\n")

# Seleccionar AAPL para análisis detallado
datos_aapl <- datos %>% 
  filter(Ticker == "AAPL") %>%
  arrange(Fecha) %>%
  mutate(log_Close = log(Close))

# Mostrar primeras observaciones
datos_aapl %>% 
  select(Fecha, Close) %>% 
  head(10) %>%
  kable(digits = 2, 
        caption = "Muestra de datos de Apple (AAPL)",
        col.names = c("Fecha", "Precio de Cierre ($)"))
```

### Visualización y transformación

```{r visualizacion-series, fig.height=8, fig.width=10, fig.cap="Serie original vs transformada logarítmicamente"}
p1 <- ggplot(datos_aapl, aes(x = Fecha, y = Close)) +
  geom_line(color = "#2c3e50", linewidth = 0.6) +
  labs(title = "Serie Original: Precio de AAPL",
       x = "Fecha", y = "Precio ($)") +
  theme_minimal()

p2 <- ggplot(datos_aapl, aes(x = Fecha, y = log_Close)) +
  geom_line(color = "#27ae60", linewidth = 0.6) +
  labs(title = "Serie Transformada: Log(Precio)",
       x = "Fecha", y = "Log(Precio)") +
  theme_minimal()

grid.arrange(p1, p2, ncol = 1)
```

**Observaciones**: La serie original muestra tendencia alcista y varianza creciente. La transformación logarítmica estabiliza la varianza.

### Análisis de estacionariedad

```{r pruebas-estacionariedad, warning=FALSE}
# Crear serie temporal
log_precio_ts <- ts(datos_aapl$log_Close, frequency = 1)

# Prueba ADF
adf_result <- adf.test(log_precio_ts)
cat("Prueba ADF:\n")
cat("P-valor:", adf_result$p.value, "\n")
cat("Conclusión:", ifelse(adf_result$p.value < 0.05, 
                          "Serie ES estacionaria", 
                          "Serie NO es estacionaria"), "\n\n")

# Prueba KPSS
kpss_result <- tryCatch({
  kpss.test(log_precio_ts, null = "Trend")
}, error = function(e) {
  list(p.value = 0.1, statistic = 0)
})

cat("Prueba KPSS:\n")
cat("P-valor:", kpss_result$p.value, "\n")
cat("Conclusión:", ifelse(kpss_result$p.value > 0.05,
                          "Serie ES estacionaria",
                          "Serie NO es estacionaria"), "\n\n")

# Prueba PP
pp_result <- pp.test(log_precio_ts)
cat("Prueba PP:\n")
cat("P-valor:", pp_result$p.value, "\n")
cat("Conclusión:", ifelse(pp_result$p.value < 0.05,
                          "Serie ES estacionaria",
                          "Serie NO es estacionaria"), "\n")
```

### Análisis ACF y PACF

```{r acf-pacf, fig.height=8, fig.width=10, fig.cap="Funciones ACF y PACF"}
par(mfrow = c(2, 1), mar = c(4, 4, 3, 2))
acf(log_precio_ts, lag.max = 40, main = "ACF de Log(Precio)")
pacf(log_precio_ts, lag.max = 40, main = "PACF de Log(Precio)")
```

**Interpretación**: El ACF muestra decaimiento gradual, sugiriendo necesidad de diferenciación. El PACF ayuda a identificar el orden AR apropiado.

## Fase 2: Estimación de Parámetros

### Estimación de modelos ARIMA

```{r estimacion-modelos, message=FALSE, warning=FALSE}
# Modelo 1: ARIMA(1,1,0)
mod_110 <- Arima(log_precio_ts, order = c(1, 1, 0))

# Modelo 2: ARIMA(0,1,1)
mod_011 <- Arima(log_precio_ts, order = c(0, 1, 1))

# Modelo 3: ARIMA(1,1,1)
mod_111 <- Arima(log_precio_ts, order = c(1, 1, 1))

# Comparación
comparacion <- data.frame(
  Modelo = c("ARIMA(1,1,0)", "ARIMA(0,1,1)", "ARIMA(1,1,1)"),
  AIC = c(mod_110$aic, mod_011$aic, mod_111$aic),
  BIC = c(mod_110$bic, mod_011$bic, mod_111$bic)
) %>% arrange(AIC)

kable(comparacion, digits = 2,
      caption = "Comparación de modelos ARIMA")
```

### Selección automática

```{r auto-arima, message=FALSE, warning=FALSE}
modelo_auto <- auto.arima(log_precio_ts, 
                          seasonal = FALSE,
                          stepwise = TRUE,
                          approximation = TRUE)

cat("Modelo seleccionado:\n")
print(modelo_auto)
cat("\nAIC:", modelo_auto$aic, "\n")
cat("BIC:", modelo_auto$bic, "\n")
```

## Fase 3: Diagnóstico

### Análisis de residuos

```{r diagnostico, fig.height=10, fig.width=10, fig.cap="Diagnóstico de residuos"}
checkresiduals(modelo_auto)
```

### Prueba de Ljung-Box

```{r ljung-box}
residuos <- residuals(modelo_auto)
lb_test <- Box.test(residuos, lag = 20, type = "Ljung-Box", 
                    fitdf = length(coef(modelo_auto)))

cat("Prueba de Ljung-Box\n")
cat("P-valor:", lb_test$p.value, "\n")
cat("Conclusión:", ifelse(lb_test$p.value > 0.05,
                          "Residuos SON ruido blanco ✓",
                          "Residuos NO son ruido blanco"), "\n")
```

## Fase 4: Pronóstico

### Generación de pronósticos

```{r pronosticos, fig.height=6, fig.width=10, fig.cap="Pronósticos ARIMA"}
# Pronósticos para 30 días
h <- 30
pronos <- forecast(modelo_auto, h = h)

# Visualizar
autoplot(pronos) +
  labs(title = "Pronósticos de Log(Precio) AAPL",
       subtitle = paste("Horizonte:", h, "días"),
       x = "Observación", y = "Log(Precio)") +
  theme_minimal()
```

### Transformación a escala original

```{r transformacion-inversa}
# Convertir a escala original
pronos_precio <- exp(pronos$mean)
li_95 <- exp(pronos$lower[, 2])
ls_95 <- exp(pronos$upper[, 2])

# Tabla de pronósticos
tabla_pronos <- data.frame(
  Día = 1:h,
  Pronóstico = pronos_precio,
  LI_95 = li_95,
  LS_95 = ls_95
)

kable(head(tabla_pronos, 10), digits = 2,
      caption = "Pronósticos de precio AAPL (primeros 10 días)",
      col.names = c("Día", "Pronóstico ($)", "LI 95% ($)", "LS 95% ($)"))
```

### Visualización final

```{r viz-final, fig.height=6, fig.width=10, fig.cap="Pronósticos en escala original"}
# Últimos 100 días + pronósticos
ultimos <- 100
hist_reciente <- tail(datos_aapl, ultimos)
ultima_fecha <- max(datos_aapl$Fecha)
fechas_futuras <- seq.Date(ultima_fecha + 1, by = "day", length.out = h)

# Combinar datos
df_viz <- bind_rows(
  hist_reciente %>% select(Fecha, Close) %>% mutate(Tipo = "Histórico"),
  data.frame(Fecha = fechas_futuras, Close = pronos_precio, Tipo = "Pronóstico")
)

df_limites <- data.frame(
  Fecha = fechas_futuras,
  LI = li_95,
  LS = ls_95
)

# Gráfico
ggplot() +
  geom_ribbon(data = df_limites, aes(x = Fecha, ymin = LI, ymax = LS),
              fill = "lightblue", alpha = 0.4) +
  geom_line(data = df_viz, aes(x = Fecha, y = Close, color = Tipo, linetype = Tipo),
            linewidth = 0.8) +
  scale_color_manual(values = c("Histórico" = "#2c3e50", "Pronóstico" = "#e74c3c")) +
  scale_linetype_manual(values = c("Histórico" = "solid", "Pronóstico" = "dashed")) +
  labs(title = "Pronósticos ARIMA para AAPL",
       subtitle = paste("Últimos", ultimos, "días +", h, "días de pronóstico"),
       x = "Fecha", y = "Precio ($)") +
  theme_minimal() +
  theme(legend.position = "bottom")
```

## Aplicación a múltiples activos

```{r multiples-activos, message=FALSE, warning=FALSE}
# Procesar todos los activos
tickers <- unique(datos$Ticker)
resultados <- list()

for (ticker in tickers) {
  # Preparar datos
  datos_ticker <- datos %>% 
    filter(Ticker == ticker) %>%
    arrange(Fecha) %>%
    mutate(log_Close = log(Close))
  
  # Crear serie temporal
  serie_ts <- ts(datos_ticker$log_Close, frequency = 1)
  
  # Ajustar modelo
  modelo <- auto.arima(serie_ts, seasonal = FALSE,
                       stepwise = TRUE, approximation = TRUE)
  
  # Guardar resultados
  resultados[[ticker]] <- list(
    modelo = modelo,
    aic = modelo$aic,
    bic = modelo$bic
  )
}

# Tabla resumen
resumen <- data.frame(
  Ticker = names(resultados),
  Modelo = sapply(resultados, function(x) as.character(x$modelo)),
  AIC = sapply(resultados, function(x) x$aic),
  BIC = sapply(resultados, function(x) x$bic)
)

kable(resumen, digits = 2,
      caption = "Modelos ARIMA seleccionados para cada activo")
```

## Conclusiones

### Hallazgos principales

1. **Estacionariedad**: La transformación logarítmica es efectiva para estabilizar la varianza en series de precios financieros.

2. **Modelos seleccionados**: Los modelos ARIMA(1,1,1) y ARIMA(2,1,1) fueron los más comunes, indicando que una diferenciación y componentes AR/MA simples son suficientes.

3. **Diagnóstico**: La mayoría de modelos pasaron las pruebas de ruido blanco, confirmando su adecuación.

### Ventajas de ARIMA

- ✓ Captura autocorrelación compleja
- ✓ Diagnóstico formal con pruebas estadísticas
- ✓ Flexibilidad en la especificación
- ✓ Intervalos de confianza para pronósticos

### Limitaciones

- Requiere series suficientemente largas
- Sensible a valores atípicos
- Asume relaciones lineales
- No modela volatilidad condicional

## Referencias

- Box, G. E. P., Jenkins, G. M., & Reinsel, G. C. (2008). *Time Series Analysis: Forecasting and Control* (4th ed.). Wiley.
- Hyndman, R. J., & Athanasopoulos, G. (2021). *Forecasting: Principles and Practice* (3rd ed.). OTexts.
- Brockwell, P. J., & Davis, R. A. (2016). *Introduction to Time Series and Forecasting* (3rd ed.). Springer.
